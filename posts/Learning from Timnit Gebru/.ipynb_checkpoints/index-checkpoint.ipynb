{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Learning from Timnit Gebru\n",
    "author: Julia Fairbank\n",
    "date: '2023-04-18'\n",
    "image: \"image.jpg\"\n",
    "description: \"A blog post reflecting on the work of Timnit Gebru.\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "Timnit Gebru is a well-known computer scientist and AI researcher, with the majority of her work focusing on bias and equity. Gebru received her bachelor's degree in computer engineering from the University of Addis Ababa, her master's degree in electrical engineering from Stanford University, and a PhD in computer vision from the University of Washington.\n",
    "\n",
    "Gebru has worked at various tech companies, including Apple, Microsoft, and Google, where she worked on creating space for underrepresented groups in AI. In 2020, after a company dispute over a research paper identifying the risks of large language models, Gebru was fired from her position as a co-lead of Google's Ethical AI team. Her removal from Google sparked widespread debate about the inherent sexism and racism in the tech industry and highlighted the importance of considering the role of ethics in AI development.\n",
    "\n",
    "Middlebury College is lucky to be joined by Timnit Gebru on Monday, April 24th for a virtual Zoom conversation discussing bias and social impacts of artificial intelligence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FATE/CV 2020 | Computer vision in practice: who is benefiting and who is being harmed?\n",
    "\n",
    "This talk discusses the importance of diversity and fair representation in the field of AI. As AI is a reflection of the programmers who developed it and will have a global impact, there is an immediate need for AI systems to be developed by a diverse set of programmers that are focused creating ethical tools that will benefit the human race, and not just be profitable. As AI spreads into the world and different industries, there are are benefits and dangers that will arise throughout. When our healthcare systems, police units, and schools use AI, the technology has the capacity to either support underrepesented groups or continue suppressing them. It is crucial for developers to identify the different biases could affect the AI systems, and ensure that these systems are trained on unbiased and well-represented data. We must hold these developers accountable for the development of these programs. \n",
    "\n",
    "tl;dr: If you train an AI on biased data, it will give you biased results; our developers are responsible for developing and training AI on fair, diverse data such that inherent biases do not get amplified by AI systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question for Timnit Gebru\n",
    "\n",
    "Do you think the changes necessary to address issues of bias and fairness in AI systems can be made the developers alone or will there need to be structural/managerial changes to the heads of the leading technology companies and/or their investment teams? If the latter, what could cause the incentive for executives to shift from profitability and towards ethical development and human wellbeing?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "debe06cc0f9553f110b64dc3926c05df82dae2145b852c8422b9c04315589dcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
